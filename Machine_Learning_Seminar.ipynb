{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Seminar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "yRvEZK30J2fW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Seminar"
      ]
    },
    {
      "metadata": {
        "id": "1ipHnl_zv8SL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Supervised Learning**\n",
        "\n",
        "The dataset contains a set of known labels or results to be predicted, i.e., the objective to be infer is known. For instance, spam vs non-spam data or whether a transaction is fraudulent or not. \n",
        "\n",
        "The training procedure consists on showing samples to the model and emiting a prediction. If the answer is wrong, the models is corrected to by updating its parameters. The training process continues until some stopping criteria is met: certain performance level or limitation of resources among others. \n",
        "\n",
        "Models in this category can be divided in two:\n",
        "\n",
        "\n",
        "*   Classification: The labels of the dataset are a categorical set. \n",
        "*   Regression: The target is a continous value. \n",
        "\n",
        "\n",
        "**Unsupervised Learning**\n",
        "\n",
        "The dataset does not contanin labels to predict. The objective consists on identifying underlying relations of the data. Samples can be grouped based on similarity. \n",
        "\n",
        "The main examples belongs to clustering and dimensionality reduciton. \n",
        "\n",
        "\n",
        "**Reinforcement Learning**"
      ]
    },
    {
      "metadata": {
        "id": "dglbVyubYqcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "82B8NJBZJ-hu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ]
    },
    {
      "metadata": {
        "id": "duCgyD2yKCP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import io\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets, metrics, preprocessing\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import rmsprop\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfTWiFsUNNC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ]
    },
    {
      "metadata": {
        "id": "p0kmyBYcJYFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr_split = 0.7\n",
        "\n",
        "# Load data\n",
        "titanic = pd.read_excel('titanic.xls')\n",
        "\n",
        "# Calculate train/test size\n",
        "rows, cols = titanic.shape\n",
        "tr_size = int(rows*tr_split)\n",
        "te_size = rows - tr_size\n",
        "\n",
        "# Split dataset\n",
        "train_df = titanic.iloc[:tr_size]\n",
        "test_df = titanic.iloc[tr_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kiKzyNFFNHqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data analysis and visualization"
      ]
    },
    {
      "metadata": {
        "id": "MW68Kjs1OL0c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   What is our target?\n",
        "*   What features are categorical?\n",
        "*   What features are numerical?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VZWG_VkdNKjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.head(n=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7bdZsMlPu--",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some feautes might be useful but if the contain null values or other errors, it might be a good idea to curate them or remove in some cases."
      ]
    },
    {
      "metadata": {
        "id": "RwLS45dEPo1y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rFnMO78QSJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_df.Age.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ri5OG5ozOqy6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We want to predict who will survive, let's start by analyzing the target features (Survived)"
      ]
    },
    {
      "metadata": {
        "id": "Yu8cDQfsMqCN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display(train_df.survived.unique())\n",
        "print('*'*30)\n",
        "display(train_df.survived.value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WVCNEXpdB_kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Target class is slightly unbalanced but it should not be an issue. If classes are 95%/5%, we would need to preprocess the number of samples in each class. There are several alternatives to solve the issue:\n",
        "\n",
        "* Downsample the overrepresented class\n",
        "* Oversample the underrepresented class\n",
        "* Modify the class weights of the classifier"
      ]
    },
    {
      "metadata": {
        "id": "AdHgRXeKRFy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pandas allows to select, group or filter with a similar syntax as SQL. Let's analyze the survival probabilities by class and/or sex. \n",
        "\n",
        "Note: *Group by* only works with discrete features."
      ]
    },
    {
      "metadata": {
        "id": "tXet07EORkbj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is the average probability of survival based on class?**"
      ]
    },
    {
      "metadata": {
        "id": "gJGv2Zb2O_0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[['pclass', 'survived']].groupby(['pclass']).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYB5zCJYRq7n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is the average probability of survival based on class AND sex?**"
      ]
    },
    {
      "metadata": {
        "id": "sHplGkM3RvLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[['pclass', 'survived', 'sex']].groupby(['pclass', 'sex']).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQmEQoe2UNz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "3HP3xyqfUN7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(train_df, col='survived')\n",
        "_ = g.map(plt.hist, 'age', bins=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OLo0xWeX91U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grid = sns.FacetGrid(train_df, col='survived')\n",
        "_ = grid.map(sns.barplot, 'sex', 'fare', alpha=.5, ci=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnljipDLjLN9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "kWtsdakzjLU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in train_df.survived.unique():\n",
        "    sns.distplot(train_df['fare'][train_df.survived==i], kde=1,label='{}'.format(i))\n",
        "\n",
        "_ = plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSSxso_kwads",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before feeding the training data to the classifier is a good practice to study the correlation between features. If some features have very high correlation, we might be able to remove them. Futhermore, is some features are highly correlated with our target class, presumably those would have a higher impact on the final decission. "
      ]
    },
    {
      "metadata": {
        "id": "YuuV62cIwalE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corr = train_df.corr()\n",
        "sns.heatmap(corr, cmap=\"YlGnBu\", annot=False)\n",
        "\n",
        "# For values, put annot=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LKzC56nkDfTr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are about to split our features and target in different arrays. To decide which features will be used for training, we need to look at their whether we have the complete information. If null values are present, we need to decide if we fill those values or remove the entire sample"
      ]
    },
    {
      "metadata": {
        "id": "Xu2zPwuRZCS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbasujW2crzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Ef-oIziYPMYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1AqOeg3wD_IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Many of the algorithms do not accept text features, let's convert the categories to discrete numerical values."
      ]
    },
    {
      "metadata": {
        "id": "dttjG4hFcrGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.loc[:, 'sex'] = train_df.sex.map({'male':1, 'female':0}, )\n",
        "train_df.loc[:, 'embarked'] = train_df.embarked.map( {'S': 0, 'C': 1, 'Q': 2})\n",
        "\n",
        "test_df.loc[:, 'sex'] = test_df.sex.map({'male':1, 'female':0}, )\n",
        "test_df.loc[:, 'embarked'] = test_df.embarked.map( {'S': 0, 'C': 1, 'Q': 2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1iIEn8ggFZov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = train_df.dropna(subset=['embarked', 'fare'])\n",
        "test_df = test_df.dropna(subset=['embarked', 'fare'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFa92EA-EMJI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To facilitate our task, let's only keep those features without null values. "
      ]
    },
    {
      "metadata": {
        "id": "EfeE8EstfHhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = train_df[['pclass', 'sex', 'sibsp','parch', 'fare', 'embarked']]\n",
        "y_train = train_df['survived']\n",
        "\n",
        "x_test = test_df[['pclass', 'sex', 'sibsp','parch', 'fare', 'embarked']]\n",
        "y_test = test_df['survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0O3KOyDiPwN4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HQr4W6sdO_J3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#scaler = preprocessing.StandardScaler()\n",
        "#scaler.fit(x_train.fare)\n",
        "\n",
        "#x_train.loc[:, 'embarked'] = scaler.transform(x_train[['fare']])\n",
        "#x_test.loc[:, 'embarked'] = scaler.transform(x_test.fare)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hkcZB10FPR0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scaler.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sa41RBJYKpaO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Supervised Learning"
      ]
    },
    {
      "metadata": {
        "id": "NwFbVKVUz9fN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ACXFBjgoHadc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "        \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.grid(None)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wFB4_uLlKsYG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Logistic Regression "
      ]
    },
    {
      "metadata": {
        "id": "CENtKVdpyzKB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "9EpSovcMK36x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt3Om8xYFMOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy %.2f\" % (accuracy*100))\n",
        "plot_confusion_matrix(cm, classes= ['class 0', 'class 1'], normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nBfm-aFK4nz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ]
    },
    {
      "metadata": {
        "id": "p9Ba8WttuJ9x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is a discriminative classifier which finds a hyperplane that separates the samples in two groups. The algorith outputs the hyperplane with the maximum margin solution.\n",
        "\n",
        "\n",
        "$\\hat{y}(x) = sgn(\\sum_{i=1}^d x_iw_i + b)$\n",
        "\n",
        "<br>\n",
        "\n",
        "A SVM is only able to find separate in two groups if they are linearly separable. In the following picut\n",
        "\n",
        "However, if the data is more complex a non linear classifier can be built using the **kernel trick**. In this case, the dot product is replaced by a non linear **kernel function**. The maximum margin hyperplane is now fit in this new feature space, usually a high dimensional space. \n",
        "\n",
        "$\\hat{y}(x) = sgn(\\sum_{i=1}^d x_iw_i + b)$"
      ]
    },
    {
      "metadata": {
        "id": "Cnl_zc5mK7X4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svc = SVC()\n",
        "svc.fit(x_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pq4urEvJbdiA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy %.2f\" % (accuracy*100))\n",
        "plot_confusion_matrix(cm, classes= ['class 0', 'class 1'], normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ccn4uTiFK___",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decission trees"
      ]
    },
    {
      "metadata": {
        "id": "RAVi0koK1-oj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Builds a tree during training time that is used during testing time to go from observations of the features (branches) to decissions (leaves). If the labels at the leaves are continous, the classifier is called regression trees. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Boosted trees: \n",
        "*   Bootstrap aggregated: \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mBjwu5LcLCMC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)\n",
        "\n",
        "y_pred = decision_tree.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRl17gyhdOv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy %.2f\" % (accuracy*100))\n",
        "plot_confusion_matrix(cm, classes= ['class 0', 'class 1'], normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tdq41fMMF_Mt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Parameter search"
      ]
    },
    {
      "metadata": {
        "id": "cm35M4anGGai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "qxtpwWCqF_nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict_classifiers = {\n",
        "    \"Logistic Regression\": \n",
        "            {'classifier': LogisticRegression(),\n",
        "                'params' : [{\n",
        "                             'penalty': ['l1','l2'],\n",
        "                             'C': [0.001,0.01,0.1,1,10,100,1000]\n",
        "                            }]\n",
        "            },\n",
        "    \"Linear SVM\": \n",
        "            {'classifier': SVC(),\n",
        "                 'params': [{\n",
        "                             'C': [1, 10],\n",
        "                             'gamma': [0.001, 0.0001],\n",
        "                             'kernel': ['linear']\n",
        "                            }]\n",
        "            },\n",
        "    \"Decision Tree\":\n",
        "            {'classifier': DecisionTreeClassifier(),\n",
        "                 'params': [{\n",
        "                             'max_depth':[3, None]\n",
        "                            }]\n",
        "            }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJcJcGpnHHzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key, classifier in dict_classifiers.items():\n",
        "        \n",
        "  grid = GridSearchCV(classifier['classifier'], \n",
        "                      classifier['params'],\n",
        "                      refit=True,\n",
        "                      cv= 2, # 9+1\n",
        "                      scoring = 'accuracy', # scoring metric\n",
        "                      n_jobs = -1)\n",
        "  estimator = grid.fit(x_train, y_train)\n",
        "\n",
        "  train_score = estimator.score(x_train,y_train)\n",
        "  test_score = estimator.score(x_test, y_test)\n",
        "    \n",
        "  print(key)\n",
        "  print(train_score)\n",
        "  print(test_score)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bc3I8xdWJ0Br",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "metadata": {
        "id": "ggOXr6PoJ0Z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HumnGCj-J0hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classif= RandomForestClassifier()\n",
        "classif.fit(X_train,label_train)\n",
        "df = pd.DataFrame()\n",
        "df['ft'] = data.columns[:-2]\n",
        "df['importance'] = classif.feature_importances_\n",
        "df = df.sort_values(by= 'importance', ascending = False)\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qRRzSDfUJ69m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_FiElmLJ8HW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['ft'] = data.columns[:-2]\n",
        "df['importance'] = classif.feature_importances_\n",
        "df = df.sort_values(by= 'importance', ascending = False)\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dK4rAgdKZvg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ft_importance = pd.DataFrame(data={'Feature':x_train.columns, 'Importance':decision_tree.feature_importances_})\n",
        "ft_importance = ft_importance.sort_values(by='Importance', ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2fQNDvjLuXI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.barplot(x=\"Feature\", y=\"Importance\", data=ft_importance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4aF28xAKvtt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Learning"
      ]
    },
    {
      "metadata": {
        "id": "HDjiOtGEUqNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HgrjjAvUr8M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "y = pd.DataFrame(data=iris.target, columns=['species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jqcAWs8WSoT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ]
    },
    {
      "metadata": {
        "id": "Rd28UycUWUOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ft_1 = 'sepal length (cm)'\n",
        "ft_2 = 'sepal width (cm)'\n",
        "\n",
        "plt.scatter(X[ft_1], X[ft_2], c=y.species.values, cmap=\"YlGnBu\")\n",
        "plt.xlabel(ft_1)\n",
        "plt.ylabel(ft_2)\n",
        "plt.title(ft_1 + ' vs ' + ft_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxGZSxN_LEYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### K-Mean"
      ]
    },
    {
      "metadata": {
        "id": "v6MfMeT0cqCF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Separates samples in n groups of equal variance based on the distance of the sample to the mean of the cluster. \n",
        "\n",
        "\n",
        "$\\sum_{i=0}^n min(||x_i-\\mu_j||^2)$\n"
      ]
    },
    {
      "metadata": {
        "id": "PrwX1YF4LHy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "ft_1 = 'sepal length (cm)'\n",
        "ft_2 = 'sepal width (cm)'\n",
        "\n",
        "plt.scatter(X[ft_1], X[ft_2], c=labels.astype(np.float), cmap=\"YlGnBu\")\n",
        "plt.xlabel(ft_1)\n",
        "plt.ylabel(ft_2)\n",
        "plt.title(ft_1 + ' vs ' + ft_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lD49KklbNko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Nearest Neighbors"
      ]
    },
    {
      "metadata": {
        "id": "dt-N_TXlKxwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn = NearestNeighbors(n_neighbors=2, algorithm='ball_tree')\n",
        "nn.fit(X)\n",
        "distances, indices = nn.kneighbors(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q45k7ddRbcub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "956NMulLzq5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "rTV5FtkddxcO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr_samples, tr_features = x_train.shape\n",
        "te_samples, _ = x_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_EYLQQSuztpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(n_features,), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84cB3J67dphe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
        "\n",
        "y_prob = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXC4QKFSeaP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = np.where(y_prob > 0.5, 1, 0)\n",
        "\n",
        "display(metrics.confusion_matrix(y_test, y_pred))\n",
        "display(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2IzQeTRvzyhp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kaggle Competition"
      ]
    },
    {
      "metadata": {
        "id": "3hMHSexSh9Wz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To practice the tecniques we have learned today, we will do a competition on https://www.kaggle.com/. \n",
        "\n",
        "Please register and join the following challenge **(TODO)**. The aim is to obtain the highest accuracy using any of the models we have learned or new ones that you would like to try. \n",
        "\n",
        "\n",
        "We have added a sample submission and the corresponding code as a reference. "
      ]
    },
    {
      "metadata": {
        "id": "eqTk9eaXj6Mp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "EBFDU_Ciz4Sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kb9n7CE9j0yC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ]
    },
    {
      "metadata": {
        "id": "-4YNV8Egj04d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9fmWLotB16BP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "GQgTugb7STMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "*  https://www.kaggle.com/amitkumarjaiswal/beginner-s-tutorial-to-titanic-using-scikit-learn"
      ]
    }
  ]
}